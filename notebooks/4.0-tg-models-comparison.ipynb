{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sklearn API like\n",
    "from ngboost import NGBClassifier\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import learning_curve\n",
    "import optuna \n",
    "import pickle\n",
    "\n",
    "sns.set(font_scale=1.5, rc={\"figure.figsize\": (12, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoder(LabelEncoder):\n",
    "    \"\"\"Override the LabelEncoder in order to use it on pipeline.\"\"\"\n",
    "\n",
    "    def fit_transform(self, y, *args, **kwargs):\n",
    "        return super().fit_transform(np.array(y).ravel()).reshape(-1, 1)\n",
    "\n",
    "    def transform(self, y, *args, **kwargs):\n",
    "        return super().transform(np.array(y).ravel()).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('../data/processed/features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.set_index('SK_ID_CURR', inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop observation with missing AMT_ANNUITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original shape %s' % features.shape[0])\n",
    "features = features[features['AMT_ANNUITY'].notnull()]\n",
    "print('New shape %i' % features.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.copy()\n",
    "features['OCCUPATION_TYPE'].replace(np.nan, 'unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_features = []\n",
    "for col in features.columns:\n",
    "    if col.startswith('CREDIT_ACTIVE') or col.endswith('_HC') or col == 'REPORTED_DPD':\n",
    "        features[col].replace(np.nan, 0, inplace=True)\n",
    "        integer_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in features.columns:\n",
    "    if not len(list(features[col].dropna().index)) == len(list(features.index)):\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scale = integer_features\n",
    "to_scale += ['DAYS_BIRTH', \n",
    "             'AMT_INCOME_TOTAL', \n",
    "             'AMT_CREDIT', \n",
    "             'AMT_ANNUITY']\n",
    "to_impute = ['EXT_SOURCE_1',\n",
    "             'EXT_SOURCE_2',\n",
    "             'EXT_SOURCE_3']\n",
    "\n",
    "column_trans = ColumnTransformer(\n",
    "    [('occupation', OneHotEncoder(dtype=int), ['OCCUPATION_TYPE']),\n",
    "     ('contract_type', LabelEncoder(), ['NAME_CONTRACT_TYPE']),\n",
    "     ('integer_features', MinMaxScaler(), integer_features),\n",
    "     ('ext_source', SimpleImputer(strategy='median'), to_impute)\n",
    "    ], remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans.fit_transform(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans.fit(features.drop(columns='TARGET'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/preprocessing_pipeline.pickle', 'wb') as f:\n",
    "    pickle.dump(column_trans, f)\n",
    "features.to_csv('../data/processed/features_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformed = column_trans.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'RandomForest': RandomForestClassifier(n_estimators=10, max_depth=75, max_features=10, max_leaf_nodes=50),\n",
    "#           'SVC': SVC(kernel='linear', cache_size=7000), # Take a long time to fit...\n",
    "          'AdaBoost': AdaBoostClassifier(),\n",
    "          'XGBoost': XGBClassifier(),\n",
    "          'LightGBM': LGBMClassifier(),\n",
    "          'NGBM': NGBClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = column_trans.fit_transform(features[features['TARGET'].notnull()].drop(columns='TARGET'))\n",
    "y = features[features['TARGET'].notnull()]['TARGET'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "print('train shape %i' % X_train.shape[0])\n",
    "print('test shape %i' % X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, cv=None, train_sizes=None):\n",
    "    if axes is None:\n",
    "        _, ax = plt.subplots(1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Training examples\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    \n",
    "    scorer = make_scorer(roc_auc_score, needs_proba=True)\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(estimator, X, y, cv=cv, scoring=scorer)\n",
    "    \n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    valid_scores_std = np.std(valid_scores, axis=1)\n",
    "    \n",
    "    ax.plot(train_sizes, train_scores_mean, label='Train score')\n",
    "    ax.plot(train_sizes, valid_scores_mean, label='Valid score')\n",
    "    \n",
    "    ax.fill_between(train_sizes, train_scores_mean + train_scores_std,\n",
    "                    train_scores_mean - train_scores_std, alpha=0.2)\n",
    "    ax.fill_between(train_sizes, valid_scores_mean + valid_scores_std,\n",
    "                    valid_scores_mean - valid_scores_std, alpha=0.2)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "fitting_time = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, m in models.items():\n",
    "    start = time.time()\n",
    "    print(\"Fitting %s\" % name)\n",
    "    m.fit(X_train, y_train)\n",
    "    fitting_time[name] = time.time() - start\n",
    "    y_pred = m.predict_proba(X_test)[:, 1]\n",
    "    score = roc_auc_score(y_test, y_pred)\n",
    "    print('ROC_AUC score %f' % score)\n",
    "    scores[name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitting_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = pd.DataFrame({\"Modèle\": list(scores.keys()),\n",
    "                          \"Score\": list(scores.values())})\n",
    "data_plot_2 = pd.DataFrame({\"Modèle\": list(fitting_time.keys()),\n",
    "                            \"Fitting time\": list(fitting_time.values())})\n",
    "data_plot.set_index('Modèle', inplace=True)\n",
    "data_plot_2.set_index('Modèle', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = pd.concat([data_plot, data_plot_2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot.rename(columns={'index': 'Modèle'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=data_plot, \n",
    "                 y='Modèle', \n",
    "                 x='Score', \n",
    "                 color='cornflowerblue')\n",
    "ax.set(xlabel='Score ROC AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(data=data_plot, y='Modèle', x='Fitting time', color='cornflowerblue')\n",
    "ax.set(xlabel='Temps de calcul CPU pour entrainement en seconde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Learning curve %s' % 'LightGBM'\n",
    "plot_learning_curve(models['LightGBM'], title, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = {x: y for x, y in zip(features.columns[:-1], model.feature_importances_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/model_v0.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit_risk",
   "language": "python",
   "name": "credit_risk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
